{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import HighD_Columns as HC \n",
    "import NGSIM_Columns as NC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_track_features(ngsim_data, NC_dict, logging = False):\n",
    "    \"\"\"\n",
    "    This method iterate on all rows of ngsim dataset sorted by vehicle ID and:\n",
    "        1. Correct vehicle ID duplication problem.\n",
    "        2. TODO:Re-calc X-/Y- Velocity/Acceleration using X and Y (all using NGSIM coordinate) after applying a filtering algorithm. \n",
    "    \"\"\"\n",
    "    current_veh_id = ngsim_data[0, NC_dict[NC.ID]] \n",
    "    correct_veh_id = ngsim_data[0,NC_dict[NC.ID]] \n",
    "    cur_t = ngsim_data[0,NC_dict[NC.GLOBAL_TIME]]\n",
    "    empty_veh_id = max(list(set(ngsim_data[:,NC_dict[NC.ID]])))+1\n",
    "    num_rows = ngsim_data.shape[0]\n",
    "    #augmented_features = np.zeros((num_rows, 4))\n",
    "    fr = 0\n",
    "    for row_itr in range(num_rows):\n",
    "        if current_veh_id != ngsim_data[row_itr, NC_dict[NC.ID]]:\n",
    "            current_veh_id = ngsim_data[row_itr, NC_dict[NC.ID]]\n",
    "            correct_veh_id = ngsim_data[row_itr, NC_dict[NC.ID]]\n",
    "            cur_t = ngsim_data[row_itr, NC_dict[NC.GLOBAL_TIME]] + 100\n",
    "            fr = 0 + 1\n",
    "            continue\n",
    "        if cur_t != ngsim_data[row_itr, NC_dict[NC.GLOBAL_TIME]]:\n",
    "            correct_veh_id = empty_veh_id\n",
    "            if logging:\n",
    "                print(\"Duplicatation found in id: \", current_veh_id, \". The id is changed to: \", correct_veh_id)\n",
    "            empty_veh_id += 1\n",
    "            ngsim_data[row_itr, NC_dict[NC.ID]] = correct_veh_id\n",
    "            cur_t = ngsim_data[row_itr, NC_dict[NC.GLOBAL_TIME]] + 100\n",
    "            fr = 0 + 1\n",
    "            continue\n",
    "        \n",
    "        ngsim_data[row_itr, NC_dict[NC.ID]] = correct_veh_id\n",
    "        \n",
    "        cur_t += 100\n",
    "        fr += 1\n",
    "    return ngsim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_frame_features(ngsim_data, NC_dict, logging = True):\n",
    "    \"\"\"\n",
    "    1. Extract vehicle IDs of surrounding vehicles.\n",
    "    2. Divide Global Time by 100\n",
    "    3. transform from feet to meter. \n",
    "    4. Reverse the order of Lane IDs\n",
    "    \"\"\"\n",
    "    SVC_dict = {\n",
    "        HC.PRECEDING_ID:0,\n",
    "        HC.FOLLOWING_ID:1,\n",
    "        HC.LEFT_PRECEDING_ID:2,\n",
    "        HC.LEFT_ALONGSIDE_ID:3,\n",
    "        HC.LEFT_FOLLOWING_ID:4,\n",
    "        HC.RIGHT_PRECEDING_ID:5,\n",
    "        HC.RIGHT_ALONGSIDE_ID:6,\n",
    "        HC.RIGHT_FOLLOWING_ID:7\n",
    "    }\n",
    "\n",
    "    sorted_ind = np.argsort(ngsim_data[:,NC_dict[NC.GLOBAL_TIME]])\n",
    "    ngsim_data = ngsim_data[sorted_ind]\n",
    "    augmented_features = np.zeros((ngsim_data.shape[0], 8))\n",
    "    all_times = sorted(list(set(ngsim_data[:,NC_dict[NC.GLOBAL_TIME]])))\n",
    "    max_itr = len(all_times)\n",
    "    for itr, g_time in enumerate(all_times):\n",
    "        if logging and itr%100 == 0:\n",
    "            print('Processing: ', itr, 'out_of: ', max_itr)\n",
    "        selected_ind = ngsim_data[:,NC_dict[NC.GLOBAL_TIME]] == g_time\n",
    "        cur_data = ngsim_data[selected_ind]\n",
    "        print(cur_data[:,NC_dict[NC.ID]])\n",
    "        cur_aug_features = augmented_features[selected_ind]\n",
    "        num_rows = cur_data.shape[0]\n",
    "        for rows_itr in range(num_rows):\n",
    "            cur_lane = cur_data[rows_itr, NC_dict[NC.LANE_ID]]\n",
    "            cur_y = cur_data[rows_itr, NC_dict[NC.Y]]\n",
    "            cur_length = cur_data[rows_itr, NC_dict[NC.LENGTH]]\n",
    "            cur_lane_sv_ind = (cur_data[:,NC_dict[NC.LANE_ID]] == cur_lane)\n",
    "            left_lane_sv_ind = (cur_data[:,NC_dict[NC.LANE_ID]] == (cur_lane-1))\n",
    "            right_lane_sv_ind = (cur_data[:,NC_dict[NC.LANE_ID]] == (cur_lane+1))\n",
    "            preceding_sv_ind = (cur_data[:,NC_dict[NC.Y]]- cur_data[:,NC_dict[NC.LENGTH]] > cur_y)\n",
    "            following_sv_ind = (cur_data[:,NC_dict[NC.Y]] < cur_y-cur_length)\n",
    "            alongside_sv_ind = np.logical_and((cur_data[:,NC_dict[NC.Y]] >= (cur_y-cur_length)), ((cur_data[:,NC_dict[NC.Y]]-cur_data[:,NC_dict[NC.LENGTH]]) <= cur_y))\n",
    "\n",
    "            #pv_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.PRECEDING_ID]] = cur_data[np.argmin(cur_data[np.logical_and(preceding_sv_ind, cur_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(preceding_sv_ind, cur_lane_sv_ind)) == True else 0\n",
    "            #fv_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.FOLLOWING_ID]] = cur_data[np.argmax(cur_data[np.logical_and(following_sv_ind, cur_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(following_sv_ind, cur_lane_sv_ind)) == True else 0\n",
    "\n",
    "            #rpv_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.RIGHT_PRECEDING_ID]] = cur_data[np.argmin(cur_data[np.logical_and(preceding_sv_ind, right_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(preceding_sv_ind, right_lane_sv_ind)) == True else 0\n",
    "            #rfv_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.RIGHT_FOLLOWING_ID]] = cur_data[np.argmax(cur_data[np.logical_and(following_sv_ind, right_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(following_sv_ind, right_lane_sv_ind)) == True else 0\n",
    "\n",
    "            #lpv_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.LEFT_PRECEDING_ID]] = cur_data[np.argmin(cur_data[np.logical_and(preceding_sv_ind, left_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(preceding_sv_ind, left_lane_sv_ind)) == True else 0\n",
    "            #lfv_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.LEFT_FOLLOWING_ID]] = cur_data[np.argmax(cur_data[np.logical_and(following_sv_ind, left_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(following_sv_ind, left_lane_sv_ind)) == True else 0\n",
    "            \n",
    "            #rav_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.RIGHT_ALONGSIDE_ID]] = cur_data[np.argmax(cur_data[np.logical_and(alongside_sv_ind, right_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(alongside_sv_ind, right_lane_sv_ind)) == True else 0\n",
    "            #lav_id\n",
    "            cur_aug_features[rows_itr,SVC_dict[HC.LEFT_ALONGSIDE_ID]] = cur_data[np.argmax(cur_data[np.logical_and(alongside_sv_ind, left_lane_sv_ind),NC_dict[NC.Y]]),0] if np.any(np.logical_and(alongside_sv_ind, left_lane_sv_ind)) == True else 0\n",
    "\n",
    "        augmented_features[selected_ind] = cur_aug_features\n",
    "\n",
    "    ngsim_data = np.concatenate((ngsim_data, augmented_features), axis = 1)\n",
    "    \n",
    "    ngsim_data[:,NC_dict[NC.GLOBAL_TIME]] = ngsim_data[:,NC_dict[NC.GLOBAL_TIME]]/100\n",
    "    ngsim_data[:,NC_dict[NC.GLOBAL_TIME]] = ngsim_data[:,NC_dict[NC.GLOBAL_TIME]] - min(ngsim_data[:,NC_dict[NC.GLOBAL_TIME]])+1\n",
    "    \n",
    "    ngsim_data[:,NC_dict[NC.X]] = 0.3048 * ngsim_data[:,NC_dict[NC.X]]\n",
    "    ngsim_data[:,NC_dict[NC.Y]] = 0.3048 * ngsim_data[:,NC_dict[NC.Y]]\n",
    "    ngsim_data[:,NC_dict[NC.LENGTH]] = 0.3048 * ngsim_data[:,NC_dict[NC.LENGTH]]\n",
    "    ngsim_data[:,NC_dict[NC.WIDTH]] = 0.3048 * ngsim_data[:,NC_dict[NC.WIDTH]]\n",
    "    ngsim_data[:,NC_dict[NC.VELOCITY]] = 0.3048 * ngsim_data[:,NC_dict[NC.VELOCITY]]\n",
    "    ngsim_data[:,NC_dict[NC.ACCELERATION]] = 0.3048 * ngsim_data[:,NC_dict[NC.ACCELERATION]]\n",
    "    ngsim_data[:,NC_dict[NC.DHW]] = 0.3048 * ngsim_data[:,NC_dict[NC.DHW]]\n",
    "    \n",
    "    ngsim_data[:,NC_dict[NC.LANE_ID]] = max(ngsim_data[:,NC_dict[NC.LANE_ID]])+1- ngsim_data[:,NC_dict[NC.LANE_ID]]\n",
    "    return ngsim_data, SVC_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ngsim_dataset = \"../../Dataset/NGSIM/Next_Generation_Simulation__NGSIM__Vehicle_Trajectories_and_Supporting.csv\"\n",
    "# Load and seperate by location\n",
    "df = pandas.read_csv(ngsim_dataset)\n",
    "ngsim = []\n",
    "locations = ['us-101', 'i-80']\n",
    "for location in locations:\n",
    "    ngsim.append(df[df[NC.LOCATION]==location])\n",
    "\n",
    "for i, location in enumerate(locations):\n",
    "    \n",
    "    # Drop undesired columns\n",
    "    ngsim[i] = ngsim[i].drop(\n",
    "                    columns = [\n",
    "                        NC.O_ZONE, \n",
    "                        NC.D_ZONE, \n",
    "                        NC.INT_ID, \n",
    "                        NC.SECTION_ID, \n",
    "                        NC.DIRECTION, \n",
    "                        NC.MOVEMENT, \n",
    "                        NC.GLOBAL_X, \n",
    "                        NC.GLOBAL_Y, \n",
    "                        NC.FRAME,\n",
    "                        NC.LOCATION, \n",
    "                        NC.TOTAL_FRAME,\n",
    "                        #NC.PRECEDING_ID,\n",
    "                        #NC.FOLLOWING_ID,\n",
    "                        ])\n",
    "    \n",
    "    # NGSIM has some duplicate rows need to be dropped\n",
    "    ngsim[i] = ngsim[i].drop_duplicates()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  0 out_of:  27726\n",
      "Processing:  100 out_of:  27726\n",
      "Processing:  200 out_of:  27726\n",
      "Processing:  300 out_of:  27726\n",
      "Processing:  400 out_of:  27726\n",
      "Processing:  500 out_of:  27726\n",
      "Processing:  600 out_of:  27726\n",
      "Processing:  700 out_of:  27726\n",
      "Processing:  800 out_of:  27726\n",
      "Processing:  900 out_of:  27726\n",
      "Processing:  1000 out_of:  27726\n",
      "Processing:  1100 out_of:  27726\n",
      "Processing:  1200 out_of:  27726\n",
      "Processing:  1300 out_of:  27726\n",
      "Processing:  1400 out_of:  27726\n",
      "Processing:  1500 out_of:  27726\n",
      "Processing:  1600 out_of:  27726\n",
      "Processing:  1700 out_of:  27726\n",
      "Processing:  1800 out_of:  27726\n",
      "Processing:  1900 out_of:  27726\n",
      "Processing:  2000 out_of:  27726\n",
      "Processing:  2100 out_of:  27726\n",
      "Processing:  2200 out_of:  27726\n",
      "Processing:  2300 out_of:  27726\n",
      "Processing:  2400 out_of:  27726\n",
      "Processing:  2500 out_of:  27726\n",
      "Processing:  2600 out_of:  27726\n",
      "Processing:  2700 out_of:  27726\n",
      "Processing:  2800 out_of:  27726\n",
      "Processing:  2900 out_of:  27726\n",
      "Processing:  3000 out_of:  27726\n",
      "Processing:  3100 out_of:  27726\n",
      "Processing:  3200 out_of:  27726\n",
      "Processing:  3300 out_of:  27726\n",
      "Processing:  3400 out_of:  27726\n",
      "Processing:  3500 out_of:  27726\n",
      "Processing:  3600 out_of:  27726\n",
      "Processing:  3700 out_of:  27726\n",
      "Processing:  3800 out_of:  27726\n",
      "Processing:  3900 out_of:  27726\n",
      "Processing:  4000 out_of:  27726\n",
      "Processing:  4100 out_of:  27726\n",
      "Processing:  4200 out_of:  27726\n",
      "Processing:  4300 out_of:  27726\n",
      "Processing:  4400 out_of:  27726\n",
      "Processing:  4500 out_of:  27726\n",
      "Processing:  4600 out_of:  27726\n",
      "Processing:  4700 out_of:  27726\n",
      "Processing:  4800 out_of:  27726\n",
      "Processing:  4900 out_of:  27726\n",
      "Processing:  5000 out_of:  27726\n",
      "Processing:  5100 out_of:  27726\n",
      "Processing:  5200 out_of:  27726\n",
      "Processing:  5300 out_of:  27726\n",
      "Processing:  5400 out_of:  27726\n",
      "Processing:  5500 out_of:  27726\n",
      "Processing:  5600 out_of:  27726\n",
      "Processing:  5700 out_of:  27726\n",
      "Processing:  5800 out_of:  27726\n",
      "Processing:  5900 out_of:  27726\n",
      "Processing:  6000 out_of:  27726\n",
      "Processing:  6100 out_of:  27726\n",
      "Processing:  6200 out_of:  27726\n",
      "Processing:  6300 out_of:  27726\n",
      "Processing:  6400 out_of:  27726\n",
      "Processing:  6500 out_of:  27726\n",
      "Processing:  6600 out_of:  27726\n",
      "Processing:  6700 out_of:  27726\n",
      "Processing:  6800 out_of:  27726\n",
      "Processing:  6900 out_of:  27726\n",
      "Processing:  7000 out_of:  27726\n",
      "Processing:  7100 out_of:  27726\n",
      "Processing:  7200 out_of:  27726\n",
      "Processing:  7300 out_of:  27726\n",
      "Processing:  7400 out_of:  27726\n",
      "Processing:  7500 out_of:  27726\n",
      "Processing:  7600 out_of:  27726\n",
      "Processing:  7700 out_of:  27726\n",
      "Processing:  7800 out_of:  27726\n",
      "Processing:  7900 out_of:  27726\n",
      "Processing:  8000 out_of:  27726\n",
      "Processing:  8100 out_of:  27726\n",
      "Processing:  8200 out_of:  27726\n",
      "Processing:  8300 out_of:  27726\n",
      "Processing:  8400 out_of:  27726\n",
      "Processing:  8500 out_of:  27726\n",
      "Processing:  8600 out_of:  27726\n",
      "Processing:  8700 out_of:  27726\n",
      "Processing:  8800 out_of:  27726\n",
      "Processing:  8900 out_of:  27726\n",
      "Processing:  9000 out_of:  27726\n",
      "Processing:  9100 out_of:  27726\n",
      "Processing:  9200 out_of:  27726\n",
      "Processing:  9300 out_of:  27726\n",
      "Processing:  9400 out_of:  27726\n",
      "Processing:  9500 out_of:  27726\n",
      "Processing:  9600 out_of:  27726\n",
      "Processing:  9700 out_of:  27726\n",
      "Processing:  9800 out_of:  27726\n",
      "Processing:  9900 out_of:  27726\n",
      "Processing:  10000 out_of:  27726\n",
      "Processing:  10100 out_of:  27726\n",
      "Processing:  10200 out_of:  27726\n",
      "Processing:  10300 out_of:  27726\n",
      "Processing:  10400 out_of:  27726\n",
      "Processing:  10500 out_of:  27726\n",
      "Processing:  10600 out_of:  27726\n",
      "Processing:  10700 out_of:  27726\n",
      "Processing:  10800 out_of:  27726\n",
      "Processing:  10900 out_of:  27726\n",
      "Processing:  11000 out_of:  27726\n",
      "Processing:  11100 out_of:  27726\n",
      "Processing:  11200 out_of:  27726\n",
      "Processing:  11300 out_of:  27726\n",
      "Processing:  11400 out_of:  27726\n",
      "Processing:  11500 out_of:  27726\n",
      "Processing:  11600 out_of:  27726\n",
      "Processing:  11700 out_of:  27726\n",
      "Processing:  11800 out_of:  27726\n",
      "Processing:  11900 out_of:  27726\n",
      "Processing:  12000 out_of:  27726\n",
      "Processing:  12100 out_of:  27726\n",
      "Processing:  12200 out_of:  27726\n",
      "Processing:  12300 out_of:  27726\n",
      "Processing:  12400 out_of:  27726\n",
      "Processing:  12500 out_of:  27726\n",
      "Processing:  12600 out_of:  27726\n",
      "Processing:  12700 out_of:  27726\n",
      "Processing:  12800 out_of:  27726\n",
      "Processing:  12900 out_of:  27726\n",
      "Processing:  13000 out_of:  27726\n",
      "Processing:  13100 out_of:  27726\n",
      "Processing:  13200 out_of:  27726\n",
      "Processing:  13300 out_of:  27726\n",
      "Processing:  13400 out_of:  27726\n",
      "Processing:  13500 out_of:  27726\n",
      "Processing:  13600 out_of:  27726\n",
      "Processing:  13700 out_of:  27726\n",
      "Processing:  13800 out_of:  27726\n",
      "Processing:  13900 out_of:  27726\n",
      "Processing:  14000 out_of:  27726\n",
      "Processing:  14100 out_of:  27726\n",
      "Processing:  14200 out_of:  27726\n",
      "Processing:  14300 out_of:  27726\n",
      "Processing:  14400 out_of:  27726\n",
      "Processing:  14500 out_of:  27726\n",
      "Processing:  14600 out_of:  27726\n",
      "Processing:  14700 out_of:  27726\n",
      "Processing:  14800 out_of:  27726\n",
      "Processing:  14900 out_of:  27726\n",
      "Processing:  15000 out_of:  27726\n",
      "Processing:  15100 out_of:  27726\n",
      "Processing:  15200 out_of:  27726\n",
      "Processing:  15300 out_of:  27726\n",
      "Processing:  15400 out_of:  27726\n",
      "Processing:  15500 out_of:  27726\n",
      "Processing:  15600 out_of:  27726\n",
      "Processing:  15700 out_of:  27726\n",
      "Processing:  15800 out_of:  27726\n",
      "Processing:  15900 out_of:  27726\n",
      "Processing:  16000 out_of:  27726\n",
      "Processing:  16100 out_of:  27726\n",
      "Processing:  16200 out_of:  27726\n",
      "Processing:  16300 out_of:  27726\n",
      "Processing:  16400 out_of:  27726\n",
      "Processing:  16500 out_of:  27726\n",
      "Processing:  16600 out_of:  27726\n",
      "Processing:  16700 out_of:  27726\n",
      "Processing:  16800 out_of:  27726\n",
      "Processing:  16900 out_of:  27726\n",
      "Processing:  17000 out_of:  27726\n",
      "Processing:  17100 out_of:  27726\n",
      "Processing:  17200 out_of:  27726\n",
      "Processing:  17300 out_of:  27726\n",
      "Processing:  17400 out_of:  27726\n",
      "Processing:  17500 out_of:  27726\n",
      "Processing:  17600 out_of:  27726\n",
      "Processing:  17700 out_of:  27726\n",
      "Processing:  17800 out_of:  27726\n",
      "Processing:  17900 out_of:  27726\n",
      "Processing:  18000 out_of:  27726\n",
      "Processing:  18100 out_of:  27726\n",
      "Processing:  18200 out_of:  27726\n",
      "Processing:  18300 out_of:  27726\n",
      "Processing:  18400 out_of:  27726\n",
      "Processing:  18500 out_of:  27726\n",
      "Processing:  18600 out_of:  27726\n",
      "Processing:  18700 out_of:  27726\n",
      "Processing:  18800 out_of:  27726\n",
      "Processing:  18900 out_of:  27726\n",
      "Processing:  19000 out_of:  27726\n",
      "Processing:  19100 out_of:  27726\n",
      "Processing:  19200 out_of:  27726\n",
      "Processing:  19300 out_of:  27726\n",
      "Processing:  19400 out_of:  27726\n",
      "Processing:  19500 out_of:  27726\n",
      "Processing:  19600 out_of:  27726\n",
      "Processing:  19700 out_of:  27726\n",
      "Processing:  19800 out_of:  27726\n",
      "Processing:  19900 out_of:  27726\n",
      "Processing:  20000 out_of:  27726\n",
      "Processing:  20100 out_of:  27726\n",
      "Processing:  20200 out_of:  27726\n",
      "Processing:  20300 out_of:  27726\n",
      "Processing:  20400 out_of:  27726\n",
      "Processing:  20500 out_of:  27726\n",
      "Processing:  20600 out_of:  27726\n",
      "Processing:  20700 out_of:  27726\n",
      "Processing:  20800 out_of:  27726\n",
      "Processing:  20900 out_of:  27726\n",
      "Processing:  21000 out_of:  27726\n",
      "Processing:  21100 out_of:  27726\n",
      "Processing:  21200 out_of:  27726\n",
      "Processing:  21300 out_of:  27726\n",
      "Processing:  21400 out_of:  27726\n",
      "Processing:  21500 out_of:  27726\n",
      "Processing:  21600 out_of:  27726\n",
      "Processing:  21700 out_of:  27726\n",
      "Processing:  21800 out_of:  27726\n",
      "Processing:  21900 out_of:  27726\n",
      "Processing:  22000 out_of:  27726\n",
      "Processing:  22100 out_of:  27726\n",
      "Processing:  22200 out_of:  27726\n",
      "Processing:  22300 out_of:  27726\n",
      "Processing:  22400 out_of:  27726\n",
      "Processing:  22500 out_of:  27726\n",
      "Processing:  22600 out_of:  27726\n",
      "Processing:  22700 out_of:  27726\n",
      "Processing:  22800 out_of:  27726\n",
      "Processing:  22900 out_of:  27726\n",
      "Processing:  23000 out_of:  27726\n",
      "Processing:  23100 out_of:  27726\n",
      "Processing:  23200 out_of:  27726\n",
      "Processing:  23300 out_of:  27726\n",
      "Processing:  23400 out_of:  27726\n",
      "Processing:  23500 out_of:  27726\n",
      "Processing:  23600 out_of:  27726\n",
      "Processing:  23700 out_of:  27726\n",
      "Processing:  23800 out_of:  27726\n",
      "Processing:  23900 out_of:  27726\n",
      "Processing:  24000 out_of:  27726\n",
      "Processing:  24100 out_of:  27726\n",
      "Processing:  24200 out_of:  27726\n",
      "Processing:  24300 out_of:  27726\n",
      "Processing:  24400 out_of:  27726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  24500 out_of:  27726\n",
      "Processing:  24600 out_of:  27726\n",
      "Processing:  24700 out_of:  27726\n",
      "Processing:  24800 out_of:  27726\n",
      "Processing:  24900 out_of:  27726\n",
      "Processing:  25000 out_of:  27726\n",
      "Processing:  25100 out_of:  27726\n",
      "Processing:  25200 out_of:  27726\n",
      "Processing:  25300 out_of:  27726\n",
      "Processing:  25400 out_of:  27726\n",
      "Processing:  25500 out_of:  27726\n",
      "Processing:  25600 out_of:  27726\n",
      "Processing:  25700 out_of:  27726\n",
      "Processing:  25800 out_of:  27726\n",
      "Processing:  25900 out_of:  27726\n",
      "Processing:  26000 out_of:  27726\n",
      "Processing:  26100 out_of:  27726\n",
      "Processing:  26200 out_of:  27726\n",
      "Processing:  26300 out_of:  27726\n",
      "Processing:  26400 out_of:  27726\n",
      "Processing:  26500 out_of:  27726\n",
      "Processing:  26600 out_of:  27726\n",
      "Processing:  26700 out_of:  27726\n",
      "Processing:  26800 out_of:  27726\n",
      "Processing:  26900 out_of:  27726\n",
      "Processing:  27000 out_of:  27726\n",
      "Processing:  27100 out_of:  27726\n",
      "Processing:  27200 out_of:  27726\n",
      "Processing:  27300 out_of:  27726\n",
      "Processing:  27400 out_of:  27726\n",
      "Processing:  27500 out_of:  27726\n",
      "Processing:  27600 out_of:  27726\n",
      "Processing:  27700 out_of:  27726\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e9941328205f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Added Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mhighD_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSVC_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngsim_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRECEDING_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRECEDING_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mhighD_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSVC_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngsim_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOLLOWING_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOLLOWING_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mhighD_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSVC_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngsim_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEFT_PRECEDING_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEFT_PRECEDING_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "for i, location in enumerate(locations):\n",
    "    # To numpy\n",
    "    ngsim[i] = ngsim[i].sort_values([NC.ID, NC.GLOBAL_TIME], ascending=[1,1])\n",
    "    ngsim_columns = ngsim[i].columns\n",
    "    ngsim_array = ngsim[i].to_numpy()\n",
    "    NC_dict = {}\n",
    "    for i,c in enumerate(ngsim_columns):\n",
    "        NC_dict[c] = i\n",
    "    assert(len(ngsim_columns)==12)\n",
    "    \n",
    "    # Transformations\n",
    "    ngsim_array = transform_track_features(ngsim_array, NC_dict)\n",
    "    ngsim_array, SVC_dict = transform_frame_features(ngsim_array, NC_dict)\n",
    "    \n",
    "    highD_columns = [None]* (len(ngsim_columns) + len(SVC_dict))\n",
    "    # Untransformed Columns\n",
    "    highD_columns[NC_dict[NC.CLASS]] = NC.CLASS\n",
    "    highD_columns[NC_dict[NC.VELOCITY]] = NC.VELOCITY # Note: Velocity is changed from feet/s to m/s\n",
    "    highD_columns[NC_dict[NC.ACCELERATION]] = NC.ACCELERATION # Note: Acceleration is changed from feet/s^2 to m/s^2 \n",
    "    highD_columns[NC_dict[NC.PRECEDING_ID]] = NC.PRECEDING_ID \n",
    "    highD_columns[NC_dict[NC.FOLLOWING_ID]] = NC.FOLLOWING_ID \n",
    "    # Transformed Columns\n",
    "    highD_columns[NC_dict[NC.ID]] = HC.TRACK_ID\n",
    "    highD_columns[NC_dict[NC.GLOBAL_TIME]] = HC.FRAME\n",
    "    highD_columns[NC_dict[NC.X]] = HC.Y # NC.X = HC.Y\n",
    "    highD_columns[NC_dict[NC.Y]] = HC.X # NC.Y = HC.X\n",
    "    highD_columns[NC_dict[NC.LENGTH]] = HC.WIDTH # NC.LENGTH = HC.WIDTH\n",
    "    highD_columns[NC_dict[NC.WIDTH]] = HC.HEIGHT # NC.WIDTH = HC.HEIGHT\n",
    "    highD_columns[NC_dict[NC.DHW]] = HC.DHW\n",
    "    highD_columns[NC_dict[NC.THW]] = HC.THW\n",
    "    highD_columns[NC_dict[NC.LANE_ID]] = HC.LANE_ID\n",
    "    \n",
    "    # Added Columns\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.PRECEDING_ID]] = HC.PRECEDING_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.FOLLOWING_ID]] = HC.FOLLOWING_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.LEFT_PRECEDING_ID]] = HC.LEFT_PRECEDING_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.LEFT_ALONGSIDE_ID]] = HC.LEFT_ALONGSIDE_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.LEFT_FOLLOWING_ID]] = HC.LEFT_FOLLOWING_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.RIGHT_PRECEDING_ID]] = HC.RIGHT_PRECEDING_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.RIGHT_ALONGSIDE_ID]] = HC.RIGHT_ALONGSIDE_ID\n",
    "    highD_columns[len(ngsim_columns) + SVC_dict[HC.RIGHT_FOLLOWING_ID]] = HC.RIGHT_FOLLOWING_ID\n",
    "    \n",
    "    # To dataframe\n",
    "    transformed_ngsim = pandas.DataFrame(data = ngsim_array, columns = highD_columns)\n",
    "    transformed_ngsim = transformed_ngsim.sort_values([HC.TRACK_ID, HC.FRAME], ascending=[1,1])\n",
    "    transformed_ngsim.to_csv(location+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.PRECEDING_ID]] = HC.PRECEDING_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.FOLLOWING_ID]] = HC.FOLLOWING_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.LEFT_PRECEDING_ID]] = HC.LEFT_PRECEDING_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.LEFT_ALONGSIDE_ID]] = HC.LEFT_ALONGSIDE_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.LEFT_FOLLOWING_ID]] = HC.LEFT_FOLLOWING_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.RIGHT_PRECEDING_ID]] = HC.RIGHT_PRECEDING_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.RIGHT_ALONGSIDE_ID]] = HC.RIGHT_ALONGSIDE_ID\n",
    "highD_columns[len(ngsim_columns) + SVC_dict[HC.RIGHT_FOLLOWING_ID]] = HC.RIGHT_FOLLOWING_ID\n",
    "\n",
    "# To dataframe\n",
    "transformed_ngsim = pandas.DataFrame(data = ngsim_array, columns = highD_columns)\n",
    "transformed_ngsim = transformed_ngsim.sort_values([HC.TRACK_ID, HC.FRAME], ascending=[1,1])\n",
    "transformed_ngsim.to_csv(location+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
